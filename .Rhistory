predict(m1,df)
head(df)
head(df[1])
head(df[2])
predict(m1,df[,1,3,4])
predict(m1,df[1,3,4])
predict(m1,df[,c(1,3,4)])
p1=predict(m1,df[,c(1,3,4)])
table(df$sleep_total,p1)
m1=rpart(sleep_total~.,data=df[1:70,],method = "anova")
p1=predict(m1,df[,c(1,3,4)])
table(df$sleep_total,p1)
setdiff(df$sleep_total,p1)
p1=predict(m1,df[71:83,c(1,3,4)])
table(df$sleep_total,p1)
table(df$sleep_total[71:83],p1)
p1
mae = function(actual,predicted){mean(abs(df$sleep_total-p1))}
mae
mae(df$sleep_total-p1)
p1
mae(df$sleep_total[71:83]-p1)
mae(df$sleep_total[71:83],p1)
length(df$sleep_total[71:83])
length(p1)
mae(df$sleep_total[71:83],p1)
mae = function(actual,predicted){return mean(abs(actual-predicted))}
mae = function(actual,predicted){return (mean(abs(actual-predicted)))}
mae(df$sleep_total[71:83],p1)
install.packages("arules")
require(arules)
data("Groceries")
itemFrequency(Groceries[,1])
inspect(Groceries[1,])
itemFrequencyPlot(Groceries)
itemFrequencyPlot(Groceries,support=0,1)
itemFrequencyPlot(Groceries,support=0.1)
m1=apriori(Groceries)
m1
m1=apriori(Groceries,parameter = list(support=0.1,confidence=0.3))
m1
m1=apriori(Groceries,parameter = list(support=0.1,confidence=0.3,minlen=2))
m1
m1=apriori(Groceries,parameter = list(support=0.01,confidence=0.3,minlen=2))
m1
m1=apriori(Groceries,parameter = list(support=0.09,confidence=0.3,minlen=2))
m1
m1=apriori(Groceries,parameter = list(support=0.07,confidence=0.3,minlen=2))
m1
summary(m1)
inspect(m1)
m1=apriori(Groceries,parameter = list(support=0.06,confidence=0.3,minlen=2))
m1
m1=apriori(Groceries,parameter = list(support=0.04,confidence=0.3,minlen=2))
m1
inspect(m1)
inspect(sort(m1,by="lift"))
inspect(sort(m1,by="lift")[1:3])
m1=apriori(Groceries,parameter = list(support=0.04,confidence=0.3,minlen=4))
m1
m1=apriori(Groceries,parameter = list(support=0.02,confidence=0.3,minlen=4))
m1
m1=apriori(Groceries,parameter = list(support=0.02,confidence=0.3,minlen=2))
m1
m1=apriori(Groceries,parameter = list(support=0.02,confidence=0.03,minlen=2))
m1
inspect(sort(m1,by="lift")[1:3])
m1=apriori(Groceries,parameter = list(support=0.007,confidence=0.03,minlen=2))
m1
m1=apriori(Groceries,parameter = list(support=0.007,confidence=0.25,minlen=2))
m1
install.packages("twitteR")
install.packages("RCurl")
Consumer_Key=OPPA5VhYKtsRugJBYyYQvIEWQ
Consumer_Key="OPPA5VhYKtsRugJBYyYQvIEWQ"
Consumer_Secret="8KAJDzmLog4Tjfwl2bMGPdqftMAN9uHdAxv01frkEZXfjrrjbT"
Access_Token=	"129692093-51O6nZGHOAluZ77k12wnaFTRi5JfndPb2J5XxyxT"
Access_Token ="0buLfcCCVtNcKlr3YClmdj4gT0cPWgz7o6k1G3JgaFYvn"
require(twitteR)
require(RCurl)
setup_twitter_oauth(Consumer_Key,Consumer_Secret,Access_Token,Access_secret)
Access_secret ="0buLfcCCVtNcKlr3YClmdj4gT0cPWgz7o6k1G3JgaFYvn"
setup_twitter_oauth(Consumer_Key,Consumer_Secret,Access_Token,Access_secret)
require(RCurl)
Consumer_Key="OPPA5VhYKtsRugJBYyYQvIEWQ"
Consumer_Secret="8KAJDzmLog4Tjfwl2bMGPdqftMAN9uHdAxv01frkEZXfjrrjbT"
Access_Token=	"129692093-51O6nZGHOAluZ77k12wnaFTRi5JfndPb2J5XxyxT"
Access_secret ="0buLfcCCVtNcKlr3YClmdj4gT0cPWgz7o6k1G3JgaFYvn"
setup_twitter_oauth(Consumer_Key,Consumer_Secret,Access_Token,Access_secret)
1
setup_twitter_oauth(Consumer_Key,Consumer_Secret,Access_Token,Access_secret)
cfc_tweets=searchTwitter("Chelsea",n=5,lang = "en")
cfc_tweets
str(cfc_tweets)
str(cfc_tweets)
cfc_tweets
data()
data("iris")
subset.data.frame(iris,subset = 1,select = 1)
subset.data.frame(iris,subset = T,select = 1)
subset.data.frame(iris,subset = T,select = 1:2)
subset.data.frame(iris,subset = T,select = 1:2)
subset.data.frame(iris,subset = T,select = c(1:2))
subset.data.frame(iris,subset = T,select = c(1:2))
subset.data.frame(iris,subset = T,select = c(1:3))
subset.data.frame(iris,subset = T,select = c(1,3))
subset.data.frame(iris,subset = F,select = c(1,3))
install.packages("tm")
install.packages("wordcloud")
require(tm)
require(wordcloud)
require(twitteR)
himearth = searchTwitter('earthquake+himalaya',lang = 'en',n = 500,resultType = 'recent')
Consumer_Key="OPPA5VhYKtsRugJBYyYQvIEWQ"
Consumer_Secret="8KAJDzmLog4Tjfwl2bMGPdqftMAN9uHdAxv01frkEZXfjrrjbT"
Access_Token=	"129692093-51O6nZGHOAluZ77k12wnaFTRi5JfndPb2J5XxyxT"
Access_secret ="0buLfcCCVtNcKlr3YClmdj4gT0cPWgz7o6k1G3JgaFYvn"
setup_twitter_oauth(Consumer_Key,Consumer_Secret,Access_Token,Access_secret)
himearth = searchTwitter('earthquake+himalaya',lang = 'en',n = 500,resultType = 'recent')
himearth = searchTwitter('chelsea',lang = 'en',n = 500,resultType = 'recent')
head(himearth)
himearth = searchTwitter('bahubali',lang = 'en',n = 500,resultType = 'recent')
head(himearth)
himearth_text=sapply(himearth, function(x) x$getText())
himearth_text
str(himearth_text)
himearth_text=sapply(himearth, function(x) x$getText())
str(himearth_text)
himearth_text=sapply(himearth, paste0,collapse="")
himearth_text=sapply(himearth, paste ,collapse="")
himearth = searchTwitter('bahubali',lang = 'en',n = 500,resultType = 'recent')
himearth_text=sapply(himearth, paste ,collapse="")
himearth_text=sapply(himearth as.character, paste ,collapse="")
himearth_text=sapply(himearth, paste ,collapse="",as.character)
himearth_text=sapply((himearth as.character, paste ,collapse="")as.character)
himearth_text=sapply((himearth as.character), paste ,collapse="")
himearth_text=sapply(himearth, paste ,coll
)
class(himearth)
unlist(himearth)
unlist(himearth,recursive = TRUE)
unlist(himearth,recursive = TRUE,use.names = FALSE)
himearth_text=unlist(himearth,recursive = TRUE,use.names = FALSE)
str(himearth_text)
class(himearth_text)
head(himearth_text)
himearth_text
require(RCurl)
Consumer_Key="OPPA5VhYKtsRugJBYyYQvIEWQ"
Consumer_Secret="8KAJDzmLog4Tjfwl2bMGPdqftMAN9uHdAxv01frkEZXfjrrjbT"
Access_Token=	"129692093-51O6nZGHOAluZ77k12wnaFTRi5JfndPb2J5XxyxT"
Access_secret ="0buLfcCCVtNcKlr3YClmdj4gT0cPWgz7o6k1G3JgaFYvn"
setup_twitter_oauth(Consumer_Key,Consumer_Secret,Access_Token,Access_secret)
himearth = searchTwitter('bahubali',lang = 'en',n = 500,resultType = 'recent')
himearth_text=unlist(himearth,recursive = TRUE,use.names = FALSE)
him_corpus=Corpus(VectorSource(himearth_text))
him_corpus
inspect(him_corpus)
inspect(him_corpus[1])
inspect(him_corpus[2])
inspect(him_corpus[2][1])
inspect(him_corpus)
him_cleam=tm_map(him_corpus,removePunctuation)
him_cleam=tm_map(him_cleam,content_transformer(tolower))
him_cleam=tm_map(him_cleam,removeWords, stopwords("english"))
him_cleam=tm_map(him_cleam,removeNumbers)
him_cleam=tm_map(him_cleam,stripWhitespace)
stopwords(English)
stopwords("English")
him_cleam=tm_map(him_cleam,removeWords,c("bahubali"))
wordcloud(him_cleam)
himearth = searchTwitter('bahubali',lang = 'en',n = 500,resultType = 'recent')
head(himearth_text)
himearth_text1=sapply(himearth, function(x) x$getText())
himearth_text1
str(himearth_text1)
class(himearth_text1)
him_corpus=Corpus(VectorSource(himearth_text1))
him_corpus
inspect(him_corpus[1])
him_cleam=tm_map(him_corpus,removePunctuation)
him_cleam=tm_map(him_cleam,content_transformer(tolower))
him_cleam=tm_map(him_cleam,removeWords, stopwords("english"))
him_cleam=tm_map(him_cleam,removeNumbers)
him_cleam=tm_map(him_cleam,stripWhitespace)
him_cleam=tm_map(him_cleam,removeWords,c("bahubali"))
wordcloud(him_cleam)
wordcloud(him_cleam,colors = rainbow(50))
wordcloud(him_cleam,colors = rainbow(30))
wordcloud(him_cleam,colors = rainbow(2))
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"))
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"))
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = F)
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = F)
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = T)
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = T)
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = T)
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = F)
himearth = searchTwitter('chelsea',lang = 'en',n = 500,resultType = 'recent')
himearth_text1=sapply(himearth, function(x) x$getText())
him_corpus=Corpus(VectorSource(himearth_text1))
inspect(him_corpus[1])
him_cleam=tm_map(him_corpus,removePunctuation)
him_cleam=tm_map(him_cleam,content_transformer(tolower))
him_cleam=tm_map(him_cleam,removeWords, stopwords("english"))
him_cleam=tm_map(him_cleam,removeNumbers)
him_cleam=tm_map(him_cleam,stripWhitespace)
him_cleam=tm_map(him_cleam,removeWords,c("bahubali"))
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = F)
him_cleam=tm_map(him_cleam,removeWords, "http%")
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = F)
him_cleam=tm_map(him_cleam,removeWords, "http*")
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = F)
him_cleam=tm_map(him_cleam,removeWords, "httpscovrhkymjnip*")
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = F)
him_cleam=tm_map(him_cleam,stripWhitespace)
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = F)
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = F)
him_cleam=tm_map(him_cleam,removeWords,c("chelsea"))
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = F)
him_cleam=tm_map(him_cleam,removeWords,"chelsea")
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = F)
himearth = searchTwitter('bahubali',lang = 'en',n = 500,resultType = 'recent')
himearth_text1=sapply(himearth, function(x) x$getText())
function (searchString, n = 25, lang = NULL, since = NULL, until = NULL,
locale = NULL, geocode = NULL, sinceID = NULL, maxID = NULL,
resultType = NULL, retryOnRateLimit = 120, ...)
himearth = searchTwitter('bahubali',lang = 'en',n = 500,resultType = 'recent')
head(himearth_text)
himearth_text1=sapply(himearth, function(x) x$getText())
himearth_text1=sapply(himearth, function(x) x$getText())
him_corpus=Corpus(VectorSource(himearth_text1))
him_corpus
him_cleam=tm_map(him_corpus,removePunctuation)
him_cleam=tm_map(him_cleam,content_transformer(tolower))
him_cleam=tm_map(him_cleam,removeWords, stopwords("english"))
him_cleam=tm_map(him_cleam,removeWords, "httpscovrhkymjnip*")
him_cleam=tm_map(him_cleam,removeNumbers)
him_cleam=tm_map(him_cleam,stripWhitespace)
him_cleam=tm_map(him_cleam,removeWords,)
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = F)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
himearth = searchTwitter('chelsea',lang = 'en',n = 500,resultType = 'recent')
head(himearth_text)
himearth_text1=sapply(himearth, function(x) x$getText())
him_corpus=Corpus(VectorSource(himearth_text1))
him_cleam=tm_map(him_corpus,removePunctuation)
him_cleam=tm_map(him_cleam,content_transformer(tolower))
him_cleam=tm_map(him_cleam,removeWords, stopwords("english"))
him_cleam=tm_map(him_cleam,removeWords, "httpscovrhkymjnip*")
him_cleam=tm_map(him_cleam,removeNumbers)
him_cleam=tm_map(him_cleam,stripWhitespace)
him_cleam=tm_map(him_cleam,removeWords,)
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = F)
himearth = searchTwitter('bahubali',lang = 'en',n = 500,resultType = 'recent')
require(tm)
require(wordcloud)
require(twitteR)
require(RCurl)
Consumer_Key="OPPA5VhYKtsRugJBYyYQvIEWQ"
Consumer_Secret="8KAJDzmLog4Tjfwl2bMGPdqftMAN9uHdAxv01frkEZXfjrrjbT"
Access_Token=	"129692093-51O6nZGHOAluZ77k12wnaFTRi5JfndPb2J5XxyxT"
Access_secret ="0buLfcCCVtNcKlr3YClmdj4gT0cPWgz7o6k1G3JgaFYvn"
setup_twitter_oauth(Consumer_Key,Consumer_Secret,Access_Token,Access_secret)
detach('package:NLP',unload = TRUE)
detach('package:tm',unload = TRUE)
detach('package:RCURL',unload = TRUE)
detach('package:RCurl',unload = TRUE)
detach("package:bitops", unload=TRUE)
detach("package:NLP", unload=TRUE)
detach("package:RColorBrewer", unload=TRUE)
detach("package:twitteR", unload=TRUE)
detach("package:wordcloud", unload=TRUE)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
himearth = searchTwitter('chelsea',lang = 'en',n = 500,resultType = 'recent')
himearth_text1=sapply(himearth, function(x) x$getText())
him_corpus=Corpus(VectorSource(himearth_text1))
him_cleam=tm_map(him_corpus,removePunctuation)
him_cleam=tm_map(him_cleam,content_transformer(tolower))
him_cleam=tm_map(him_cleam,removeWords, stopwords("english"))
him_cleam=tm_map(him_cleam,removeWords, "httpscovrhkymjnip*")
him_cleam=tm_map(him_cleam,removeNumbers)
him_cleam=tm_map(him_cleam,stripWhitespace)
him_cleam=tm_map(him_cleam,removeWords,)
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = F,scale = c(3,0.5))
wordcloud(him_cleam,colors = brewer.pal(8, "Dark2"),random.color = T,random.order = F,scale = c(5,0.5))
data()
data("Adult")
require(tm)
require(twitteR)
require(RCurl)
Consumer_Key="OPPA5VhYKtsRugJBYyYQvIEWQ"
Consumer_Secret ="8KAJDzmLog4Tjfwl2bMGPdqftMAN9uHdAxv01frkEZXfjrrjbT"
Access_Token=	"129692093-51O6nZGHOAluZ77k12wnaFTRi5JfndPb2J5XxyxT"
Access_Token_Secret=	"0buLfcCCVtNcKlr3YClmdj4gT0cPWgz7o6k1G3JgaFYvn"
setup_twitter_oauth(consumer_key = Consumer_Key,consumer_secret = Consumer_Secret,access_token = Access_Token,access_secret = Access_Token_Secret)
chels_tweets=searchTwitter("chelsea",n = 500,lang = "en",resultType = 'recent')
require(tm)
chels_tweets=searchTwitter("chelsea",n = 500,lang = "en",resultType = 'recent')
require(tm)
print("a")
chels_tweets=searchTwitter("chelsea",n = 500,lang = "en",resultType = 'recent')
chels_char=lapply(chels_tweets, function(x) x$getText())
head(chels_tweets)
head(chels_char)
class(chels_char)
chels_char=sapply(chels_tweets, function(x) x$getText())
class(chels_char)
head(chels_char)
chels_clean=tm_map(chels_char,tolower(chels_char))
chels_clean=Corpus(chels_char)
chels_clean=Corpus(VectorSource(chels_char))
chels_clean=tm_map(chels_char,tolower(chels_char))
chels_clean=tm_map(chels_char,removePunctuation)
chels_clean=tm_map(chels_clean,removePunctuation)
chels_clean=tm_map(chels_clean,content_transformer(tolower))
chels_clean=tm_map(chels_clean,removeWords,stopwords("english"))
chels_clean=tm_map(chels_clean,removeNumbers)
chels_clean=tm_map(chels_clean,stripWhitespace)
chels_clean=tm_map(chels_clean,removeWords,c("chelsea"))
wordcloud(chels_clean,scale = c(5,0.7),random.order = F,colors =brewer.pal(8, "Dark2") )
source('~/.active-rstudio-document')
wordcloud(chels_clean,scale = c(5,0.7),random.order = F,colors =brewer.pal(8, "Dark2") )
wordcloud(chels_clean,scale = c(5,0.7),random.order = F,colors =brewer.pal(4, "Dark2") )
grep("helse",chels_clean)
grep("helse",chels_char)
grep("helse",chels_char,value = TRUE)
grep("Luiz",chels_char,value = TRUE)
wordcloud(chels_clean,scale = c(5,0.7),random.order = F,colors =brewer.pal(4, "Dark3") )
wordcloud(chels_clean,scale = c(5,0.7),random.order = F,colors =brewer.pal(6, "Dark3") )
wordcloud(chels_clean,scale = c(5,0.7),random.order = F,colors =brewer.pal(6, "Dark8") )
wordcloud(chels_clean,scale = c(5,0.7),random.order = F,colors =brewer.pal(6, "Dark2") )
grep("helse",chels_clean,value = TRUE)
grep("helse",as.character(chels_clean),value = TRUE)
length(grep("helse",as.character(chels_clean),value = TRUE))
class(grep("helse",as.character(chels_clean),value = TRUE))
grep(pattern = "helse",as.character(chels_clean),value = TRUE)
grep(pattern = "helse",x=as.character(chels_clean),value = TRUE)
grep(pattern = "helse",x=as.character(chels_clean),value = TRUE,perl = TRUE)
grep(pattern = "helse",x=as.character(chels_clean),value = TRUE,perl = FALSE)
grep(pattern = "helse",x=as.character(chels_clean),value = TRUE,fixed = T)
grep(pattern = "helse",x=as.character(chels_clean),value = TRUE,fixed = F)
grep(pattern = "helse",x=as.character(chels_clean),value = TRUE,useBytes = T)
grep(pattern = "helse",x=as.character(chels_clean),value = TRUE,useBytes = F)
grep(pattern = "helse",x=as.character(chels_clean),value = TRUE)
sub("luiz",chels_char)
sub("luiz","",chels_char)
sub("luiz","",chels_clean)
regexpr(pattern = "luiz",chels_char)
regexpr(pattern = "luiz",chels_char,useBytes = )
regexpr(pattern = "luiz",chels_char,useBytes = T)
regexpr(pattern = "luiz",chels_char,useBytes = F)
regexpr(pattern = "luiz",text = chels_char,)
regexpr(pattern = "luiz",text = chels_char)
regexpr(pattern = "luiz",text = chels_char,useBytes = T)
regexpr(pattern = "luiz",text = chels_char,perl = T)
regexpr(pattern = "luiz",text = chels_char)
regexpr(pattern = "luiz",text = chels_clean)
regexpr(pattern = "luiz",text = chels_char)
chels_char[1]
chels_char[2]
class(chels_char)
chels_char(regexpr(pattern = "luiz",text = chels_char))
chels_char[regexpr(pattern = "luiz",text = chels_char)]
chels_char[regexpr(pattern = "arsenal",text = chels_char)]
grep(pattern = "arsenal",x = chels_char)
grep(pattern = "luiz",x = chels_char)
grep(pattern = "luiz",x = chels_char,value = T)
grep(pattern = "luiz",x = chels_clean,value = T)
grep(pattern = "luiz",x = chels_char,value = T)
grep(pattern = "luiz",x = chels_char,value = T)
source('~/.active-rstudio-document')
warnings()
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
source('~/.active-rstudio-document')
chels_clean=tm_map(chels_clean,removeWords,sub("http*"))
chels_clean=tm_map(chels_clean,removeWords,sub("http*",chels_clean))
chels_clean=tm_map(chels_clean,removeWords,sub("http*",x = chels_clean))
head(Adult)
head(Adult)
class(Adult)
data("Titanic")
head(Titanic)
head(Titanic)
class(Titanic)
source('C:/Users/nirva/IdeaProjects/R/TwitterCloudR/TwitterWordCloud.R')
require(MASS)
data("Aids2")
head(Aids2)
Aids=Aids2
Aids$state=as.numeric(factor(Aids$state,levels = unique(Aids$state)))
Aids$status=as.numeric(factor(Aids$status,levels = unique(Aids$status)))
Aids$sex=as.numeric(factor(Aids$sex,levels = unique(Aids$sex)))
Aids$T.categ=as.numeric(factor(Aids$T.categ,levels = unique(Aids$T.categ)))
head(Aids2)
head(Aids)
Aids$LAD=0
head(Aids)
Aids_D=Aids[Aids$status==2]
Aids_D=Aids[Aids$status==2,]
Aids_A=Aids[Aids$status==1,]
Aids_D_train=Aids_D[1:1000]
Aids_D_train=Aids_D[1:1000,]
Aids_D_test=Aids_D[1001:1082,]
head(Aids)
Aids_D_train$LAD=Aids_D_train$death-Aids_D_train$diag
head(Aids)
head(Aids_D_train)
logistic=glm(Aids_D_train$LAD~Aids_D_train$sex+Aids_D_train$death)
class(predict(logistic))
predict(logistic)
predict(logistic[1])
predict(logistic)[1]
logistic=glm(Aids_D_train$LAD~Aids_D_train$state+Aids_D_train$diag+Aids_D_train$sex+Aids_D_train$death+Aids_D_train$status+Aids_D_train$T.categ+Aids_D_train$age)
predict(logistic)[1]
predict(logistic)[2]
Aids_D_train$LAD[1]
Aids_D_train$LAD[2]
predict(logistic)[1:10]
Aids_D_train$LAD[1:10]
predict(object = logistic)[900:910]
Aids_D_train$LAD[900:910]
head(Aids_D_test)
drop(x =Aids_D_test$LAD)
head(Aids_D_test)
Aids_D_test=Aids_D_test[,1:7]
predict(object = logistic,Aids_D_test)
?predict
logistic=lm(Aids_D_train$LAD~Aids_D_train$state+Aids_D_train$diag+Aids_D_train$sex+Aids_D_train$death+Aids_D_train$status+Aids_D_train$T.categ+Aids_D_train$age)
predict(object = logistic,Aids_D_test,)
predict(object = logistic)
logistic=lm(Aids_D_train$LAD~Aids_D_train$state+Aids_D_train$diag+Aids_D_train$sex+Aids_D_train$death+Aids_D_train$status+Aids_D_train$T.categ+Aids_D_train$age)
predict(object = logistic)[1:10]
Aids_D_train$LAD[900:910][1:10]
predict(object = logistic)[1:10]
Aids_D_train$LAD[1:10]
predict(object = logistic,type='response')      #[1:10]
predict(object = logistic,type='response')      [1:10]
Aids_D_train$LAD[1:10]
predict(object = logistic,Aids_D_test,type='response')      [1:10]
dim(predict(object = logistic,Aids_D_test,type='response')      )#[1:10]
class(predict(object = logistic,Aids_D_test,type='response')      )#[1:10]
predict(object = logistic,Aids_D_test,type='response')
Aids_D_train1=Aids_D_train[,1:7]
predict(object = logistic,Aids_D_train1)
predict(object = logistic,Aids_D_train1)[1:10]
Aids_D_train$LAD[1:10]
install.packages('bnlearn')
require(bnlearn)
data(gaussian.test)
training.set = gaussian.test[1:4000, ] # This is training set to learn the parameters
test.set = gaussian.test[4001:4010, ]  # This is test set to give as evidence
res = hc(training.set)                 # learn BN structure on training set data
View(Aids_D_train1)
res[1]
res
fitted = bn.fit(res, training.set)     # learning of parameters
pred = predict(fitted$C, test.set)     # predicts the value of node C given test set
fitted
table(pred, test.set[, "C"])           # compares the predicted value as original
install.packages('forecast')
require(forecast)
predict(object = logistic,Aids_D_train1)
predict(object = logistic,Aids_D_train
Aids_D_train$LAD[1:10]
accuracy(f = pred, x = test.set[, "C"])
predict(object = logistic,Aids_D_train
Aids_D_train$LAD[1:10]
accuracy(f = pred, x = test.set[, "C"])
predict(object = logistic,Aids_D_train)
logistic=lm(Aids_D_train$LAD~Aids_D_train$state+Aids_D_train$diag+Aids_D_train$sex+Aids_D_train$death+Aids_D_train$status+Aids_D_train$T.categ+Aids_D_train$age)
predict(object = logistic)
pred=predict(object = logistic)
accuracy(f = pred, Aids_D_train$LAD)
accuracy(f = pred, Aids_D_train$LAD)
?accuracy
intersect(pred, Aids_D_train$LAD)
length(intersect(pred, Aids_D_train$LAD))
source('C:/Users/nirva/IdeaProjects/R/Whatsapp chat analysis/WhatsappChat analysis.R')
getwd()
source('C:/Users/nirva/IdeaProjects/R/Whatsapp chat analysis/WhatsappChat analysis.R')
source('C:/Users/nirva/IdeaProjects/R/Whatsapp chat analysis/WhatsappChat analysis.R')
source('C:/Users/nirva/IdeaProjects/R/Whatsapp chat analysis/WhatsappChat analysis.R')
lib=c('tm','plyr','class','stringr','wordcloud')
lapply(lib,require,character.only=T)
wordcloud(words)
str(words)
class(words)
words=unlist(words)
class(words)
wordcloud(words)
wordcloud(words,random.order=FALSE, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
wordcloud(words,random.order=FALSE,max.words = 200, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
source('C:/Users/nirva/IdeaProjects/R/Whatsapp chat analysis/WhatsappChat analysis.R')
source('C:/Users/nirva/IdeaProjects/R/Whatsapp chat analysis/WhatsappChat analysis.R')
wordcloud(words,random.order=FALSE,max.words = 300, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
source('C:/Users/nirva/IdeaProjects/R/Whatsapp chat analysis/WhatsappChat analysis.R')
source('C:/Users/nirva/IdeaProjects/R/Whatsapp chat analysis/WhatsappChat analysis.R')
source('C:/Users/nirva/IdeaProjects/R/Whatsapp chat analysis/WhatsappChat analysis.R')
source('C:/Users/nirva/IdeaProjects/R/Whatsapp chat analysis/WhatsappChat analysis.R')
